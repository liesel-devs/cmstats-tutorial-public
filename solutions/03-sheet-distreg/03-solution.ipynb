{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Solutions Sheet 03\n",
        "format: \n",
        "  html:\n",
        "    standalone: true\n",
        "    toc: true\n",
        "execute: \n",
        "  cache: false\n",
        "  echo: fenced\n",
        "engine: knitr\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{{< include ../math.qmd >}}\n",
        "\n",
        "\\solution{03}\n",
        "\n",
        "On Google Colab, you can install the required libraries with the following\n",
        "commands:\n",
        "\n",
        "```\n",
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz\n",
        "!pip install liesel\n",
        "!pip install plotnine\n",
        "```\n",
        "\n",
        "\n",
        "## Exercise 1: A Location-Scale Regression Model\n",
        "\n",
        "We start by loading the data and importing the relevant libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import tensorflow_probability.substrates.jax.distributions as tfd\n",
        "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
        "import jax.numpy as jnp\n",
        "import liesel.model as lsl\n",
        "import liesel.goose as gs\n",
        "\n",
        "rent99 = pd.read_csv(\"https://s.gwdg.de/mzAkHV\")\n",
        "\n",
        "area = rent99.area.to_numpy(\"float32\")\n",
        "rent = rent99.rent.to_numpy(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is different about this model is the fact that we are defining a covariate\n",
        "model for the scale of the response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Observed covariate values\n",
        "x = lsl.obs(area, name=\"area\")\n",
        "\n",
        "g0 = lsl.param(0.0, name=\"g0\")\n",
        "g1 = lsl.param(0.0, lsl.Dist(tfd.Normal, loc=0., scale=10.), name=\"g1\")\n",
        "\n",
        "def linear_model(x, intercept, slope):\n",
        "    return intercept + x*slope\n",
        "\n",
        "log_sigma = lsl.Var(\n",
        "  lsl.Calc(linear_model, x=x, intercept=g0, slope=g1), \n",
        "  name=\"log_sigma\"\n",
        ")\n",
        "\n",
        "sigma = lsl.Var(lsl.Calc(jnp.exp, log_sigma), name=\"sigma\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rest works the same as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Location Model\n",
        "b0 = lsl.param(0.0, name=\"b0\")\n",
        "b1 = lsl.param(0.0, lsl.Dist(tfd.Normal, loc=0., scale=10.), name=\"b1\")\n",
        "\n",
        "mu = lsl.Var(lsl.Calc(linear_model, x=x, intercept=b0, slope=b1), name=\"mu\")\n",
        "\n",
        "# Observation Model\n",
        "y_dist = lsl.Dist(tfd.Normal, loc=mu, scale=sigma)\n",
        "y = lsl.obs(rent, y_dist, name=\"rent\")\n",
        "\n",
        "# Build Graph & Plot\n",
        "gb = lsl.GraphBuilder().add(y)\n",
        "gb.plot_vars()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sampling from the posterior using Goose also works the same as before.\n",
        "The only difference here is that we have to think of sampling the regression\n",
        "coefficients of the scale model instead of sampling the log variance directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = gb.build_model()\n",
        "interface = gs.LieselInterface(model)\n",
        "\n",
        "eb = gs.EngineBuilder(seed=1, num_chains=4)\n",
        "eb.add_kernel(gs.NUTSKernel([\"b0\", \"b1\"]))\n",
        "eb.add_kernel(gs.IWLSKernel([\"g0\", \"g1\"]))\n",
        "\n",
        "eb.set_duration(warmup_duration=1000, posterior_duration=1000)\n",
        "eb.set_model(interface)\n",
        "eb.set_initial_values(model.state)\n",
        "eb.set_engine_seed(seed=2)\n",
        "\n",
        "engine = eb.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After building the engine, it's time to sample and then summarize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "engine.sample_all_epochs()\n",
        "results = engine.get_results()\n",
        "summary = gs.Summary(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(summary.to_dataframe())\n",
        "print(summary.error_df())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have a quick look at the trace plots for $\\beta_1$ and $\\gamma_1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gs.plot_param(results, \"b1\")\n",
        "gs.plot_param(results, \"g1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: A semiparametric model with `{rliesel}`\n",
        "\n",
        "### Subtask a): Plotting the dataset\n",
        "\n",
        "We import the data and, like before, use `plotnine` for plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from plotnine import ggplot, aes, geom_line, geom_point, geom_ribbon, labs\n",
        "\n",
        "mcycle = pd.read_csv(\"https://s.gwdg.de/50F2v6\")\n",
        "\n",
        "(\n",
        "  ggplot(mcycle)\n",
        "  + aes(\"times\", \"accel\")\n",
        "  + geom_point()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask b): Set up an `rliesel` model\n",
        "\n",
        "- Rliesel offers a syntax interface that is very similar to the common modeling\n",
        "interfaces in R. \n",
        "- Notably, we can use `mgcv` functionality to define smooth functions with the function `s()`. See `?s` for help on this function.\n",
        "- Under the hood, Liesel will set up a default distributional regression \n",
        "  configuration including priors for us.\n",
        "  \n",
        "The R code is:\n",
        "\n",
        "```{r}\n",
        "library(rliesel)\n",
        "library(reticulate)\n",
        "```\n",
        "\n",
        "```{r}\n",
        "mcycle <- py$mcycle\n",
        "```\n",
        "\n",
        "```{r}\n",
        "model <- liesel(\n",
        "  \n",
        "  response = mcycle$accel,\n",
        "  distribution = \"Normal\",\n",
        "  \n",
        "  predictors = list(\n",
        "    loc = predictor(~s(times, bs = \"ps\", k=20), inverse_link = \"Identity\"),\n",
        "    scale = predictor(~1, inverse_link = \"Exp\")\n",
        "  ),\n",
        "  \n",
        "  data = mcycle\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "```{{python}}\n",
        "#| include: false\n",
        "#| echo: false\n",
        "model = r.model\n",
        "lsl.save_model(model, \"ex2-model.pickle\")\n",
        "```\n",
        "\n",
        "In pure Python, we import a prepared model object from the public tutorial\n",
        "repoository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from urllib.request import urlopen\n",
        "import dill\n",
        "\n",
        "model = dill.load(urlopen(\"https://s.gwdg.de/un4W29\"))\n",
        "\n",
        "# model = lsl.load_model(\"path/to/model.pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask c): Plot the model\n",
        "\n",
        "Let's plot the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lsl.plot_vars(model, save_path=\"img/loc.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask d): Default sampling scheme\n",
        "\n",
        "Describe the default sampling scheme for a semi-parametric distributional regression model, i.e. the different kernels for the different parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "engine_builder = lsl.dist_reg_mcmc(model, seed=1337, num_chains=4)\n",
        "engine_builder.set_duration(warmup_duration=1000, posterior_duration=1000)\n",
        "\n",
        "params = [name for name, var in model.vars.items() if var.parameter]\n",
        "\n",
        "kernel_idx = []\n",
        "kernel_cls = []\n",
        "\n",
        "for param in params:\n",
        "    for i, kernel in enumerate(engine_builder.kernels):\n",
        "        if param in kernel.position_keys:\n",
        "            kernel_idx.append(i)\n",
        "            kernel_cls.append(kernel.__class__.__name__)\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"param\": params,\n",
        "    \"kernel_idx\": kernel_idx,\n",
        "    \"kernel_cls\": kernel_cls,\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask e): Draw posterior samples\n",
        "\n",
        "For a default distributional regression model, Liesel ships the convenience\n",
        "function `lsl.dist_reg_mcmc`, which sets up a fully prepared `gs.EngineBuilder`\n",
        "for us to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "engine_builder = lsl.dist_reg_mcmc(model, seed=1337, num_chains=4)\n",
        "engine_builder.set_duration(warmup_duration=1000, posterior_duration=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For easier plotting later on, we tell Goose to include the values of the\n",
        "`\"loc\"` node in the posterior samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "engine_builder.positions_included.append(\"loc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we run the sampling scheme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "engine = engine_builder.build()\n",
        "engine.sample_all_epochs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask f): Inspect results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = engine.get_results()\n",
        "summary = gs.Summary(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(summary.to_dataframe())\n",
        "print(summary.error_df())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some trace plots:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gs.plot_trace(results, \"loc_np0_beta\", range(0, 9))\n",
        "gs.plot_trace(results, \"loc_np0_beta\", range(9, 19))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask g): Visualize estimated P-Spline\n",
        "\n",
        "Now we make use of the fact that we tracked the value of the location. We can \n",
        "easily access summary statistics from the summary object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loc = summary.quantities[\"mean\"][\"loc\"]\n",
        "loc_hdi = summary.quantities[\"hdi\"][\"loc\"]\n",
        "\n",
        "loc_hdi_lo = loc_hdi[0,:]\n",
        "loc_hdi_hi = loc_hdi[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For plotting, we again use `plotnine`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "  ggplot()\n",
        "  + aes(x = mcycle.times)\n",
        "  + geom_point(aes(y = mcycle.accel))\n",
        "  + geom_line(aes(y = loc))\n",
        "  + geom_ribbon(aes(ymin = loc_hdi_lo, ymax = loc_hdi_hi), alpha = 0.2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Distributional regression with  `{rliesel}`\n",
        "\n",
        "\n",
        "### Subtask a): Model setup\n",
        "\n",
        "Model setup works similar - we just have to additionally define a covariate\n",
        "model for the scale now.\n",
        "\n",
        "```{{r}}\n",
        "model <- liesel(\n",
        "  response = mcycle$accel,\n",
        "  distribution = \"Normal\",\n",
        "  predictors = list(\n",
        "    loc = predictor(~s(times, bs = \"ps\", k = 20), inverse_link = \"Identity\"),\n",
        "    scale = predictor(~s(times, bs = \"ps\", k = 20), inverse_link = \"Exp\")\n",
        "  ),\n",
        "  data = mcycle\n",
        ")\n",
        "```\n",
        "\n",
        "```{{python}}\n",
        "#| include: false\n",
        "#| echo: false\n",
        "model = r.model\n",
        "lsl.save_model(model, \"ex3-model.pickle\")\n",
        "```\n",
        "\n",
        "For Python-only participants, we load the model from the public\n",
        "repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = dill.load(urlopen(\"https://s.gwdg.de/exn3LQ\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask b): Plot your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lsl.plot_vars(model, save_path=\"img/locscale.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtasks c), d): Set up engine builder, sample and inspect\n",
        "\n",
        "Like before, we can quickly set up the sampling scheme with our little helper\n",
        "`lsl.dist_reg_mcmc`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "engine_builder = lsl.dist_reg_mcmc(model, seed=11, num_chains=4)\n",
        "\n",
        "engine_builder.set_duration(warmup_duration=1000, posterior_duration=1000)\n",
        "engine_builder.positions_included += [\"loc\", \"scale\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's one tricky bit here: the default jittering, which adds \n",
        "uniformly distributed random noise $u \\sim \\mathcal{U}(-2, 2)$ to the starting\n",
        "values,\n",
        "is too aggressive\n",
        "for the for scale regression \n",
        "coefficients. So we have to override the a manual jittering with a more\n",
        "subtle version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import jax\n",
        "\n",
        "def jitter_scale_coefs(key, coef):\n",
        "   jittering = jax.random.uniform(\n",
        "     key, coef.shape, minval=-0.1, maxval=0.1\n",
        "   )\n",
        "   return coef + jittering\n",
        "\n",
        "engine_builder.set_jitter_fns({\"scale_np0_beta\": jitter_scale_coefs})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can sample successfully:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "engine = engine_builder.build()\n",
        "engine.sample_all_epochs()\n",
        "results = engine.get_results()\n",
        "summary = gs.Summary(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(summary.to_dataframe())\n",
        "print(summary.error_df())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask e): Plot results for mean function\n",
        "\n",
        "And go on to plot our results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loc = summary.quantities[\"mean\"][\"loc\"]\n",
        "loc_hdi = summary.quantities[\"hdi\"][\"loc\"]\n",
        "\n",
        "loc_hdi_lo = loc_hdi[0,:]\n",
        "loc_hdi_hi = loc_hdi[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "  ggplot()\n",
        "  + aes(x = mcycle.times)\n",
        "  + geom_point(aes(y = mcycle.accel))\n",
        "  + geom_line(aes(y = loc))\n",
        "  + geom_ribbon(aes(ymin = loc_hdi_lo, ymax = loc_hdi_hi), alpha = 0.2, fill = \"blue\")\n",
        "  + labs(title = \"Shaded: HDI for mean function\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask f): Plot results for scale function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scale = summary.quantities[\"mean\"][\"scale\"]\n",
        "scale_hdi = summary.quantities[\"hdi\"][\"scale\"]\n",
        "\n",
        "scale_hdi_lo = scale_hdi[0,:]\n",
        "scale_hdi_hi = scale_hdi[1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the scale estimate to display one standard deviation around the mean\n",
        "estimate:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "  ggplot()\n",
        "  + aes(x = mcycle.times)\n",
        "  + geom_point(aes(y = mcycle.accel))\n",
        "  + geom_line(aes(y = loc))\n",
        "  + geom_ribbon(aes(ymin = loc - scale, ymax = loc + scale), alpha = 0.2, fill = \"red\")\n",
        "  + labs(title = \"Shaded: +- 1 SD around mean function\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or we can plot the scale directly as a function of our covariate, including\n",
        "uncertainty visualization with highest posterior density intervals:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "(\n",
        "  ggplot()\n",
        "  + aes(x = mcycle.times)\n",
        "  + geom_line(aes(y = scale))\n",
        "  + geom_ribbon(aes(ymin = scale_hdi_lo, ymax = scale_hdi_hi), alpha = 0.2, fill = \"blue\")\n",
        "  + labs(title = \"Scale function. Shaded: HDI for scale function\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Recover the statistical model for the scale\n",
        "\n",
        "Let's load the model again and plot the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = dill.load(urlopen(\"https://s.gwdg.de/un4W29\"))\n",
        "lsl.plot_vars(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Information from the graph:\n",
        "\n",
        "- `\"scale_p0\"` is the only term in the scale predictor.\n",
        "- It has the inputs `\"scale_p0_X\"` and `\"scale_p0_beta\"`.\n",
        "\n",
        "Let's look at these variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.vars[\"scale_p0_X\"].value\n",
        "model.vars[\"scale_p0_beta\"].value\n",
        "model.vars[\"scale_p0_beta\"].value.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The variable `\"scale_p0_X\"` is just a one-column matrix of ones, looking like\n",
        "   the intercept-column of a design matrix.\n",
        "- The variable `\"scale_p0_beta\"` is a scalar parameter.\n",
        "\n",
        "Now how do the values enter `\"scale_p0\"`? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.vars[\"scale_p0\"].weak"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The variable `\"scale_p0\"` is weak, so we can assume that it wraps a calculator.\n",
        "We can access the calculator through the `lsl.Var.value_node` attribute. Then,\n",
        "we can access the function wrapped by the calculator through the \n",
        "`lsl.Calc.function` attribute. Python's `inspect.getsource()` function allows\n",
        "us to print the code that defined this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import inspect\n",
        "\n",
        "inspect.getsource(model.vars[\"scale_p0\"].value_node.function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can thus see that we have a model of the form:\n",
        "$$\n",
        "\\bseta_{\\sigma} = \\bfX_{\\sigma} \\bsbeta_{\\sigma},\n",
        "$$\n",
        "where $\\bfX_{\\sigma} = \\bfone$ and $\\bsbeta_{\\sigma} = \\beta_{\\sigma}$. Since we\n",
        "have specified the exponential function as the inverse link function in our\n",
        "call to `rliesel::liesel`, we now know that we have\n",
        "$$\n",
        "\\sigma = \\exp(\\eta_{\\sigma}) = \\exp(\\beta_\\sigma),\n",
        "$$\n",
        "so $\\beta_\\sigma$ in our model, represented by the variable\n",
        "`\"scale_p0_beta\"`, is the logarithm of the scale. Note that we have switched\n",
        "back to scalar notation here, because the model assumes a constant scale.\n",
        "\n",
        "Now what is the prior that `rliesel` assigned for us? Let's take a closer look\n",
        "at the `\"scale_p0_beta\"` variable and its `lsl.Var.dist_node` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.vars[\"scale_p0_beta\"].dist_node\n",
        "model.vars[\"scale_p0_beta\"].dist_node.distribution\n",
        "model.vars[\"scale_p0_beta\"].dist_node.distribution.__name__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tells us: $\\beta_\\sigma$ has a normal prior. Now what are the location and\n",
        "scale of this prior? We can get this insight through the `lsl.Node.kwinputs`\n",
        "attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.vars[\"scale_p0_beta\"].dist_node.kwinputs\n",
        "model.vars[\"scale_p0_beta\"].dist_node.kwinputs[\"loc\"].value\n",
        "model.vars[\"scale_p0_beta\"].dist_node.kwinputs[\"scale\"].value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we know now that the prior is specified as\n",
        "$$\n",
        "\\beta_\\sigma \\sim \\mathcal{N}\\bigl(0, 100^2\\bigr),\n",
        "$$\n",
        "which makes the prior for $\\sigma$ \n",
        "$$\n",
        "\\sigma \\sim \\text{Lognormal}\\bigl(0, 100^2\\bigr).\n",
        "$$"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}